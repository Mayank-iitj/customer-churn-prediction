{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ca2829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from preprocessing import DataPreprocessor, load_data\n",
    "from model_training import ChurnModelTrainer, split_data\n",
    "from evaluation import ModelEvaluator\n",
    "from utils import create_sample_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ad3f0d",
   "metadata": {},
   "source": [
    "## 1. Generate Sample Data (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f398bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample dataset for demonstration\n",
    "df = create_sample_dataset(n_samples=1000, output_path='../data/sample_customer_churn.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654474d6",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65284f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data\n",
    "df = load_data('../data/sample_customer_churn.csv')\n",
    "print(f\"Loaded {len(df)} records with {len(df.columns)} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f86ec1e",
   "metadata": {},
   "source": [
    "## 3. Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fa2a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize preprocessor\n",
    "preprocessor = DataPreprocessor(scaling_method='standard')\n",
    "\n",
    "# Run preprocessing pipeline\n",
    "X, y = preprocessor.preprocess_pipeline(\n",
    "    df, \n",
    "    target_column='Churn',\n",
    "    encoding_method='onehot',\n",
    "    handle_imbalance=False\n",
    ")\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Churn rate: {y.mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf46eb6",
   "metadata": {},
   "source": [
    "## 4. Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55865cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train, validation, and test sets\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = split_data(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    val_size=0.1, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(X_train)} samples\")\n",
    "print(f\"Validation set: {len(X_val)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed14db43",
   "metadata": {},
   "source": [
    "## 5. Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8da43d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer\n",
    "trainer = ChurnModelTrainer(random_state=42)\n",
    "\n",
    "# Initialize models\n",
    "models = trainer.initialize_models()\n",
    "print(f\"Initialized {len(models)} models:\")\n",
    "for name in models.keys():\n",
    "    print(f\"  - {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22fd70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train baseline models\n",
    "cv_results = trainer.train_baseline_models(X_train, y_train, cv_folds=5)\n",
    "\n",
    "# Display results\n",
    "for name, results in cv_results.items():\n",
    "    print(f\"{name}: {results['mean_score']:.4f} (+/- {results['std_score']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d432ed8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune hyperparameters for top 3 models\n",
    "top_models = sorted(cv_results.items(), key=lambda x: x[1]['mean_score'], reverse=True)[:3]\n",
    "top_model_names = [name for name, _ in top_models]\n",
    "\n",
    "print(f\"Tuning hyperparameters for: {top_model_names}\")\n",
    "\n",
    "tuned_models = trainer.tune_hyperparameters(\n",
    "    X_train, y_train,\n",
    "    model_names=top_model_names,\n",
    "    search_method='grid',\n",
    "    cv_folds=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b41fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select best model\n",
    "best_name, best_model, best_score = trainer.select_best_model(X_val, y_val)\n",
    "\n",
    "print(f\"\\nBest Model: {best_name}\")\n",
    "print(f\"Validation Score: {best_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938472a4",
   "metadata": {},
   "source": [
    "## 6. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f6a4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize evaluator\n",
    "evaluator = ModelEvaluator()\n",
    "\n",
    "# Get feature names\n",
    "feature_names = list(X.columns) if hasattr(X, 'columns') else [f\"Feature_{i}\" for i in range(X.shape[1])]\n",
    "\n",
    "# Evaluate best model\n",
    "metrics = evaluator.evaluate_model(\n",
    "    best_model,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    feature_names=feature_names,\n",
    "    model_name=best_name\n",
    ")\n",
    "\n",
    "print(\"\\nTest Set Performance:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63f4a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all models\n",
    "comparison_df = evaluator.compare_models(trainer.models, X_test, y_test)\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724e328c",
   "metadata": {},
   "source": [
    "## 7. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a27492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importance (for tree-based models)\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    importance_df = evaluator.plot_feature_importance(\n",
    "        best_model, \n",
    "        feature_names, \n",
    "        top_n=15\n",
    "    )\n",
    "    display(importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dddbdb",
   "metadata": {},
   "source": [
    "## 8. Make Predictions on New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ff6879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample new customer\n",
    "new_customer = pd.DataFrame([{\n",
    "    'gender': 'Male',\n",
    "    'SeniorCitizen': 0,\n",
    "    'Partner': 'Yes',\n",
    "    'Dependents': 'No',\n",
    "    'tenure': 12,\n",
    "    'PhoneService': 'Yes',\n",
    "    'MultipleLines': 'No',\n",
    "    'InternetService': 'Fiber optic',\n",
    "    'OnlineSecurity': 'No',\n",
    "    'OnlineBackup': 'No',\n",
    "    'DeviceProtection': 'No',\n",
    "    'TechSupport': 'No',\n",
    "    'StreamingTV': 'Yes',\n",
    "    'StreamingMovies': 'Yes',\n",
    "    'Contract': 'Month-to-month',\n",
    "    'PaperlessBilling': 'Yes',\n",
    "    'PaymentMethod': 'Electronic check',\n",
    "    'MonthlyCharges': 85.0,\n",
    "    'TotalCharges': 1020.0\n",
    "}])\n",
    "\n",
    "# Preprocess new customer (using fitted preprocessor)\n",
    "X_new, _ = preprocessor.preprocess_pipeline(\n",
    "    new_customer,\n",
    "    target_column='Churn',  # Will be ignored for prediction data\n",
    "    fit=False  # Use already fitted transformers\n",
    ")\n",
    "\n",
    "# Make prediction\n",
    "prediction = best_model.predict(X_new)\n",
    "probability = best_model.predict_proba(X_new)\n",
    "\n",
    "print(f\"\\nChurn Prediction: {'Churn' if prediction[0] == 1 else 'No Churn'}\")\n",
    "print(f\"Churn Probability: {probability[0][1]*100:.2f}%\")\n",
    "print(f\"Retention Probability: {probability[0][0]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba415d14",
   "metadata": {},
   "source": [
    "## 9. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a757f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "import joblib\n",
    "\n",
    "model_path = trainer.save_model(filepath='../models/best_churn_model.pkl')\n",
    "print(f\"Model saved to: {model_path}\")\n",
    "\n",
    "# Save preprocessor\n",
    "preprocessor_path = '../models/preprocessor.pkl'\n",
    "joblib.dump(preprocessor, preprocessor_path)\n",
    "print(f\"Preprocessor saved to: {preprocessor_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee24aad",
   "metadata": {},
   "source": [
    "## 10. Load and Use Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccaab40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved model\n",
    "loaded_model = joblib.load('../models/best_churn_model.pkl')\n",
    "loaded_preprocessor = joblib.load('../models/preprocessor.pkl')\n",
    "\n",
    "print(\"Model and preprocessor loaded successfully!\")\n",
    "\n",
    "# Use loaded model for prediction\n",
    "# (preprocessing and prediction code same as above)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68489483",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. ✅ Data generation/loading\n",
    "2. ✅ Data preprocessing\n",
    "3. ✅ Train/validation/test split\n",
    "4. ✅ Model training (multiple algorithms)\n",
    "5. ✅ Hyperparameter tuning\n",
    "6. ✅ Model evaluation\n",
    "7. ✅ Feature importance\n",
    "8. ✅ Making predictions\n",
    "9. ✅ Saving/loading models\n",
    "\n",
    "You can now:\n",
    "- Customize the preprocessing pipeline\n",
    "- Train with your own data\n",
    "- Experiment with different models\n",
    "- Make predictions on new customers\n",
    "- Deploy models in production"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
