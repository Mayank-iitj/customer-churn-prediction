{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa29f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# For better display\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6114cf02",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cde0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "# Note: Update the path to your actual data file\n",
    "df = pd.read_csv('../data/customer_churn.csv')\n",
    "\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(f\"Number of Rows: {df.shape[0]:,}\")\n",
    "print(f\"Number of Columns: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da921d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800074d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types and info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c51fdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f0d2b5",
   "metadata": {},
   "source": [
    "## 2. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86128ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_data = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Missing_Count': df.isnull().sum(),\n",
    "    'Missing_Percentage': (df.isnull().sum() / len(df) * 100).round(2)\n",
    "})\n",
    "\n",
    "missing_data = missing_data[missing_data['Missing_Count'] > 0].sort_values('Missing_Count', ascending=False)\n",
    "print(\"\\nMissing Values Summary:\")\n",
    "print(missing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ccc291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize missing values\n",
    "if len(missing_data) > 0:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(missing_data['Column'], missing_data['Missing_Percentage'])\n",
    "    plt.xlabel('Missing Percentage (%)')\n",
    "    plt.title('Missing Values by Column')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No missing values found in the dataset!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffed035b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"\\nNumber of duplicate rows: {duplicates}\")\n",
    "if duplicates > 0:\n",
    "    print(f\"Percentage of duplicates: {(duplicates / len(df) * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3c3bae",
   "metadata": {},
   "source": [
    "## 3. Univariate Analysis\n",
    "\n",
    "### Target Variable Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c999b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable distribution (adjust column name as needed)\n",
    "target_col = 'Churn'  # Update this to match your dataset\n",
    "\n",
    "if target_col in df.columns:\n",
    "    churn_counts = df[target_col].value_counts()\n",
    "    churn_pct = df[target_col].value_counts(normalize=True) * 100\n",
    "    \n",
    "    print(\"Churn Distribution:\")\n",
    "    print(churn_counts)\n",
    "    print(\"\\nPercentage:\")\n",
    "    print(churn_pct.round(2))\n",
    "    \n",
    "    # Visualize\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Count plot\n",
    "    axes[0].bar(churn_counts.index.astype(str), churn_counts.values, color=['green', 'red'])\n",
    "    axes[0].set_xlabel('Churn Status')\n",
    "    axes[0].set_ylabel('Count')\n",
    "    axes[0].set_title('Churn Distribution (Count)')\n",
    "    for i, v in enumerate(churn_counts.values):\n",
    "        axes[0].text(i, v + 50, str(v), ha='center', va='bottom')\n",
    "    \n",
    "    # Pie chart\n",
    "    axes[1].pie(churn_counts.values, labels=churn_counts.index, autopct='%1.1f%%',\n",
    "                colors=['green', 'red'], startangle=90)\n",
    "    axes[1].set_title('Churn Distribution (Percentage)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Check for class imbalance\n",
    "    imbalance_ratio = churn_pct.max() / churn_pct.min()\n",
    "    print(f\"\\nClass Imbalance Ratio: {imbalance_ratio:.2f}:1\")\n",
    "    if imbalance_ratio > 2:\n",
    "        print(\"⚠️ Significant class imbalance detected. Consider using SMOTE or class weights.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032623b5",
   "metadata": {},
   "source": [
    "### Numerical Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046e5228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numerical columns\n",
    "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "if target_col in numerical_cols:\n",
    "    numerical_cols.remove(target_col)\n",
    "\n",
    "print(f\"Numerical Features ({len(numerical_cols)}):\")\n",
    "print(numerical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c4313d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of numerical features\n",
    "if len(numerical_cols) > 0:\n",
    "    n_cols = 3\n",
    "    n_rows = (len(numerical_cols) + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5 * n_rows))\n",
    "    axes = axes.flatten() if n_rows > 1 else [axes]\n",
    "    \n",
    "    for idx, col in enumerate(numerical_cols):\n",
    "        axes[idx].hist(df[col].dropna(), bins=30, edgecolor='black', alpha=0.7)\n",
    "        axes[idx].set_title(f'Distribution of {col}')\n",
    "        axes[idx].set_xlabel(col)\n",
    "        axes[idx].set_ylabel('Frequency')\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    for idx in range(len(numerical_cols), len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5784e181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots for outlier detection\n",
    "if len(numerical_cols) > 0:\n",
    "    n_cols = 3\n",
    "    n_rows = (len(numerical_cols) + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5 * n_rows))\n",
    "    axes = axes.flatten() if n_rows > 1 else [axes]\n",
    "    \n",
    "    for idx, col in enumerate(numerical_cols):\n",
    "        axes[idx].boxplot(df[col].dropna())\n",
    "        axes[idx].set_title(f'Box Plot of {col}')\n",
    "        axes[idx].set_ylabel(col)\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    for idx in range(len(numerical_cols), len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a40bca",
   "metadata": {},
   "source": [
    "### Categorical Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00dc693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical columns\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "if target_col in categorical_cols:\n",
    "    categorical_cols.remove(target_col)\n",
    "\n",
    "print(f\"Categorical Features ({len(categorical_cols)}):\")\n",
    "print(categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87c422f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of categorical features\n",
    "if len(categorical_cols) > 0:\n",
    "    for col in categorical_cols:\n",
    "        print(f\"\\n{col} - Value Counts:\")\n",
    "        print(df[col].value_counts())\n",
    "        print(f\"Unique values: {df[col].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dba143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize categorical features\n",
    "if len(categorical_cols) > 0:\n",
    "    n_cols = 2\n",
    "    n_rows = (len(categorical_cols) + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5 * n_rows))\n",
    "    axes = axes.flatten() if n_rows > 1 else [axes] if len(categorical_cols) == 1 else axes\n",
    "    \n",
    "    for idx, col in enumerate(categorical_cols):\n",
    "        value_counts = df[col].value_counts()\n",
    "        axes[idx].bar(range(len(value_counts)), value_counts.values)\n",
    "        axes[idx].set_xticks(range(len(value_counts)))\n",
    "        axes[idx].set_xticklabels(value_counts.index, rotation=45, ha='right')\n",
    "        axes[idx].set_title(f'Distribution of {col}')\n",
    "        axes[idx].set_ylabel('Count')\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    for idx in range(len(categorical_cols), len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08933440",
   "metadata": {},
   "source": [
    "## 4. Bivariate Analysis\n",
    "\n",
    "### Numerical Features vs Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daf64d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare numerical features across churn groups\n",
    "if target_col in df.columns and len(numerical_cols) > 0:\n",
    "    n_cols = 2\n",
    "    n_rows = (len(numerical_cols) + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5 * n_rows))\n",
    "    axes = axes.flatten() if n_rows > 1 else [axes] if len(numerical_cols) == 1 else axes\n",
    "    \n",
    "    for idx, col in enumerate(numerical_cols):\n",
    "        df.boxplot(column=col, by=target_col, ax=axes[idx])\n",
    "        axes[idx].set_title(f'{col} by Churn Status')\n",
    "        axes[idx].set_xlabel('Churn')\n",
    "        axes[idx].set_ylabel(col)\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    for idx in range(len(numerical_cols), len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.suptitle('')  # Remove default title\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf622e9",
   "metadata": {},
   "source": [
    "### Categorical Features vs Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86367ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Churn rate by categorical features\n",
    "if target_col in df.columns and len(categorical_cols) > 0:\n",
    "    for col in categorical_cols:\n",
    "        # Calculate churn rate for each category\n",
    "        churn_rate = df.groupby(col)[target_col].apply(lambda x: (x == 1).sum() / len(x) * 100)\n",
    "        \n",
    "        print(f\"\\nChurn Rate by {col}:\")\n",
    "        print(churn_rate.sort_values(ascending=False))\n",
    "        \n",
    "        # Visualize\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        \n",
    "        # Stacked bar chart\n",
    "        pd.crosstab(df[col], df[target_col]).plot(kind='bar', stacked=True, ax=axes[0])\n",
    "        axes[0].set_title(f'Churn Distribution by {col}')\n",
    "        axes[0].set_xlabel(col)\n",
    "        axes[0].set_ylabel('Count')\n",
    "        axes[0].legend(title='Churn', labels=['No', 'Yes'])\n",
    "        axes[0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Churn rate bar chart\n",
    "        churn_rate.plot(kind='bar', ax=axes[1], color='coral')\n",
    "        axes[1].set_title(f'Churn Rate by {col}')\n",
    "        axes[1].set_xlabel(col)\n",
    "        axes[1].set_ylabel('Churn Rate (%)')\n",
    "        axes[1].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9573b55",
   "metadata": {},
   "source": [
    "## 5. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ef26d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix for numerical features\n",
    "if len(numerical_cols) > 0:\n",
    "    # Include target if it's numerical\n",
    "    corr_cols = numerical_cols.copy()\n",
    "    if target_col in df.columns and df[target_col].dtype in ['int64', 'float64']:\n",
    "        corr_cols.append(target_col)\n",
    "    \n",
    "    correlation_matrix = df[corr_cols].corr()\n",
    "    \n",
    "    # Plot correlation heatmap\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "                center=0, square=True, linewidths=1)\n",
    "    plt.title('Correlation Matrix of Numerical Features')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Top correlations with target\n",
    "    if target_col in corr_cols:\n",
    "        target_corr = correlation_matrix[target_col].drop(target_col).sort_values(ascending=False)\n",
    "        print(\"\\nTop Correlations with Target:\")\n",
    "        print(target_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d416b55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify highly correlated features (multicollinearity)\n",
    "if len(numerical_cols) > 0:\n",
    "    high_corr_threshold = 0.8\n",
    "    high_corr_pairs = []\n",
    "    \n",
    "    for i in range(len(correlation_matrix.columns)):\n",
    "        for j in range(i+1, len(correlation_matrix.columns)):\n",
    "            if abs(correlation_matrix.iloc[i, j]) > high_corr_threshold:\n",
    "                high_corr_pairs.append((\n",
    "                    correlation_matrix.columns[i],\n",
    "                    correlation_matrix.columns[j],\n",
    "                    correlation_matrix.iloc[i, j]\n",
    "                ))\n",
    "    \n",
    "    if high_corr_pairs:\n",
    "        print(f\"\\nHighly Correlated Feature Pairs (|correlation| > {high_corr_threshold}):\")\n",
    "        for feat1, feat2, corr in high_corr_pairs:\n",
    "            print(f\"{feat1} <-> {feat2}: {corr:.3f}\")\n",
    "        print(\"\\n⚠️ Consider removing one feature from each highly correlated pair.\")\n",
    "    else:\n",
    "        print(f\"\\nNo highly correlated feature pairs found (threshold: {high_corr_threshold})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e9104f",
   "metadata": {},
   "source": [
    "## 6. Key Insights and Findings\n",
    "\n",
    "### Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6f2c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary insights\n",
    "print(\"=\"*80)\n",
    "print(\"KEY INSIGHTS FROM EXPLORATORY DATA ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n1. Dataset Overview:\")\n",
    "print(f\"   - Total Records: {len(df):,}\")\n",
    "print(f\"   - Total Features: {len(df.columns)}\")\n",
    "print(f\"   - Numerical Features: {len(numerical_cols)}\")\n",
    "print(f\"   - Categorical Features: {len(categorical_cols)}\")\n",
    "\n",
    "if target_col in df.columns:\n",
    "    churn_rate = (df[target_col] == 1).sum() / len(df) * 100\n",
    "    print(f\"\\n2. Churn Statistics:\")\n",
    "    print(f\"   - Overall Churn Rate: {churn_rate:.2f}%\")\n",
    "    print(f\"   - Churned Customers: {(df[target_col] == 1).sum():,}\")\n",
    "    print(f\"   - Retained Customers: {(df[target_col] == 0).sum():,}\")\n",
    "\n",
    "missing_total = df.isnull().sum().sum()\n",
    "print(f\"\\n3. Data Quality:\")\n",
    "print(f\"   - Total Missing Values: {missing_total:,}\")\n",
    "print(f\"   - Duplicate Rows: {duplicates}\")\n",
    "\n",
    "print(\"\\n4. Recommendations:\")\n",
    "if missing_total > 0:\n",
    "    print(\"   - Handle missing values through imputation or removal\")\n",
    "if duplicates > 0:\n",
    "    print(\"   - Remove duplicate records\")\n",
    "if 'imbalance_ratio' in locals() and imbalance_ratio > 2:\n",
    "    print(\"   - Address class imbalance using SMOTE or class weights\")\n",
    "if high_corr_pairs:\n",
    "    print(\"   - Consider feature selection to handle multicollinearity\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ac7b10",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Based on this EDA, the following steps are recommended:\n",
    "\n",
    "1. **Data Preprocessing**:\n",
    "   - Handle missing values\n",
    "   - Encode categorical variables\n",
    "   - Scale numerical features\n",
    "   - Engineer new features if needed\n",
    "\n",
    "2. **Feature Selection**:\n",
    "   - Remove highly correlated features\n",
    "   - Select most important features for modeling\n",
    "\n",
    "3. **Model Training**:\n",
    "   - Train multiple classification models\n",
    "   - Perform hyperparameter tuning\n",
    "   - Use cross-validation\n",
    "\n",
    "4. **Model Evaluation**:\n",
    "   - Evaluate using appropriate metrics (ROC-AUC, F1-score, etc.)\n",
    "   - Analyze feature importance\n",
    "   - Generate interpretability insights"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
